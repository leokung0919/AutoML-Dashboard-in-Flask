{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432b8821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leo\\AppData\\Local\\Temp/ipykernel_30004/3761173232.py:7: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "C:\\Users\\leo\\AppData\\Local\\Temp/ipykernel_30004/3761173232.py:8: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "C:\\Users\\leo\\AppData\\Local\\Temp/ipykernel_30004/3761173232.py:10: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  from dash_table.Format import Format\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output,State\n",
    "from dash_table.Format import Format\n",
    "import dash_table\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input,callback_context\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "import dash\n",
    "from flask import Flask\n",
    "import dash_bootstrap_components as dbc\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "import base64\n",
    "import io\n",
    "from category_encoders import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import fetch_openml\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from dash.exceptions import PreventUpdate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import re\n",
    "import joblib\n",
    "import optuna\n",
    "import sys\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860083a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDash2:\n",
    "    def __init__(self):\n",
    "        #資料\n",
    "        self.data_frame = None\n",
    "        self.data_frame2 = None\n",
    "        self.target_column=None\n",
    "        \n",
    "        #訓練和預測\n",
    "        self.train_outcome=None\n",
    "        self.result=None\n",
    "        \n",
    "        #防呆\n",
    "        self.beforeclicks=None #之前點擊的次數\n",
    "        self.page=1 #點的那一頁(預設第一頁)\n",
    "        \n",
    "        \n",
    "    def placeholder_figure(self):\n",
    "        placeholder_figure = go.Figure(data=[],\n",
    "                                       layout=go.Layout(xaxis=dict(title='X Axis Title'),\n",
    "                                                        yaxis=dict(title='Y Axis Title'),\n",
    "                                                        margin=dict(l=40, r=40, t=10, b=20)))\n",
    "        return placeholder_figure\n",
    "    \n",
    "    def run_dash(self):\n",
    "        \n",
    "        #sidebar的樣式\n",
    "        SIDEBAR_STYLE = {\n",
    "            \"position\": \"fixed\",\n",
    "            \"top\": 0,\n",
    "            \"left\": 0,\n",
    "            \"bottom\": 0,\n",
    "            \"width\": \"16rem\",\n",
    "            \"padding\": \"2rem 1rem\",\n",
    "            \"background-color\": \"#f8f9fa\",\n",
    "            'font-size': '18px'\n",
    "        }\n",
    "        \n",
    "        #內容的樣式\n",
    "        CONTENT_STYLE = {\n",
    "            \"margin-left\": \"18rem\", \n",
    "            \"margin-right\": \"2rem\",\n",
    "            \"padding\": \"2rem 1rem\",\n",
    "        }\n",
    "        \n",
    "        #sidebar\n",
    "        sidebar = html.Div([\n",
    "            dbc.Nav([\n",
    "                dbc.NavLink('Current Data',href='/page0',id='link_0'),\n",
    "                html.Hr(className='my-2', style={'border-top': '1.5px solid rgb(125, 125, 125)'}),  \n",
    "                dbc.Accordion(\n",
    "                    [\n",
    "                        dbc.AccordionItem(\n",
    "                            [dbc.Nav([\n",
    "                                dbc.NavLink('Data Uploading',href='/page1',id='link_1'),\n",
    "                                dbc.NavLink('Data EDA', href='/page2',id='link_2'),\n",
    "                                dbc.NavLink('Missing Value Imputing',href='/page3',id='link_3'),\n",
    "                                ], vertical=True, pills=True, navbar=True,style={'marginLeft':'20px'}),],title='Data Preparation'),\n",
    "                        dbc.AccordionItem(\n",
    "                            [dbc.Nav([\n",
    "                                dbc.NavLink('Encoding',href='/page4',id='link_4'),\n",
    "                                dbc.NavLink('Standardization', href='/page5',id='link_5'),\n",
    "                                ], vertical=True, pills=True, navbar=True,style={'marginLeft':'20px'}),],title='Feature Engineering'),\n",
    "                        dbc.AccordionItem(\n",
    "                            [dbc.Nav([\n",
    "                                dbc.NavLink('Introduction',href='/page6',id='link_6'),\n",
    "                                dbc.NavLink('Filter Method', href='/page7',id='link_7'),\n",
    "                                dbc.NavLink('Wrapper Method', href='/page8',id='link_8'),\n",
    "                                dbc.NavLink('Embedded Method', href='/page9',id='link_9'),\n",
    "                                ], vertical=True, pills=True, navbar=True,style={'marginLeft':'20px'}),],title=\"Feature Selection\"),\n",
    "                        dbc.AccordionItem(\n",
    "                            [dbc.Nav([\n",
    "                                dbc.NavLink('Prediction', href='/page10',id='link_10'),\n",
    "                                ], vertical=True, pills=True, navbar=True,style={'marginLeft':'20px'}),],title=\"Prediction\")\n",
    "                    ],flush=True,start_collapsed=True),\n",
    "                html.Hr(style={'border-top': '1.5px solid rgb(125, 125, 125)'}), \n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "            ),\n",
    "        ],\n",
    "        style=SIDEBAR_STYLE)\n",
    "\n",
    "    \n",
    "        modal = html.Div([\n",
    "            dbc.Modal([\n",
    "                dbc.ModalHeader(\n",
    "                    dbc.ModalTitle(\"Reminding\"), close_button=False),\n",
    "                    dbc.ModalBody(\n",
    "                        \"This part you have done already \"\n",
    "                        \"Try clicking the below close button.\"\n",
    "                    ),\n",
    "                    dbc.ModalFooter(dbc.Button(\"Close\", id=\"close-dismiss\")),],\n",
    "                    id=\"modal-dismiss\",\n",
    "                    keyboard=False,\n",
    "                    backdrop=\"static\")])\n",
    "        \n",
    "        \n",
    "        \n",
    "        content = html.Div(id=\"page-content\", children=[], style=CONTENT_STYLE)\n",
    "        \n",
    "        \n",
    "        app = Dash(__name__,\n",
    "                external_stylesheets=[dbc.themes.MINTY],\n",
    "                suppress_callback_exceptions=True\n",
    "        )\n",
    "        \n",
    "        app.layout = html.Div([\n",
    "            modal,\n",
    "            dcc.Location(id='url', refresh=False), #獲取當前的URL路徑，以根據URL路徑顯示相應的內容。 \n",
    "            sidebar,\n",
    "            content\n",
    "        ])\n",
    "        \n",
    "        LINK_0_STYLE = {\"color\": \"rgb(178, 136, 102)\"} \n",
    "        DEFAULT_STYLE = {\"color\": \"rgb(147, 202, 173)\"} \n",
    "        ACTIVE_STYLE = {\"color\": \"rgb(238, 145, 125)\"} \n",
    "\n",
    "        @app.callback(\n",
    "            [Output(f\"link_{i}\", \"style\") for i in range(11)],\n",
    "            [Input(f\"link_{i}\", \"n_clicks\") for i in range(11)],\n",
    "            State(\"url\", \"pathname\")\n",
    "        )\n",
    "        def highlight_links(*args):\n",
    "            \n",
    "            n_clicks = args[:-1]\n",
    "            pathname = args[-1]\n",
    "            styles = [LINK_0_STYLE] + [DEFAULT_STYLE] * 10\n",
    "            for i, _ in enumerate(n_clicks[1:], 1):\n",
    "                active = re.search(r\"page(\\d+)\", pathname)  \n",
    "                if active and int(active.group(1)) == i:\n",
    "                    styles[i] = ACTIVE_STYLE\n",
    "                elif n_clicks[i] : \n",
    "                    styles[i] = {\"color\": \"rgb(100, 100, 100)\"}\n",
    "            return styles\n",
    "        \n",
    "        @app.callback(\n",
    "            Output(\"modal-dismiss\", \"is_open\"),\n",
    "            [Input(f\"link_{i}\", \"n_clicks\") for i in range(11)],\n",
    "            Input(\"close-dismiss\", \"n_clicks\"),\n",
    "            State(\"modal-dismiss\", \"is_open\"),\n",
    "        )\n",
    "        def poke(*args):\n",
    "            n_clicks = args[:-2]\n",
    "            n_close=args[-2]\n",
    "            is_open=args[-1]\n",
    "            n_clicks=list(n_clicks)\n",
    "            for i in range(len(n_clicks)):\n",
    "                if n_clicks[i] is None:\n",
    "                    n_clicks[i]=0\n",
    "            n_clicks=tuple(n_clicks)\n",
    "            \n",
    "            if self.beforeclicks is not None:\n",
    "                for i in range(len(self.beforeclicks)):\n",
    "                    if n_clicks[i]!=self.beforeclicks[i]:\n",
    "                        self.page=i\n",
    "            self.beforeclicks=n_clicks\n",
    "            \n",
    "            if self.page ==0: \n",
    "                return is_open\n",
    "            elif self.page ==2: \n",
    "                return is_open\n",
    "            elif self.page ==6: \n",
    "                return is_open\n",
    "            elif self.page ==10: \n",
    "                return is_open\n",
    "            \n",
    "            if n_clicks[self.page] is not None and n_clicks[self.page]>1:\n",
    "                return not is_open\n",
    "            elif n_clicks[self.page] or n_close:\n",
    "                return is_open\n",
    "            else:\n",
    "                return is_open\n",
    "\n",
    "        \n",
    "# =======================================================================================================================\n",
    "\n",
    "        #第零頁 檔案現況\n",
    "        page0_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                html.H1(\"Current Data\",id='current'),\n",
    "                html.Br(),\n",
    "                #train data\n",
    "                html.H3('Train Data'),\n",
    "                html.Hr(),\n",
    "                html.Br(),\n",
    "                html.Div(id='train-data-upload-result0',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                #test data\n",
    "                html.H3('Test Data'),\n",
    "                html.Hr(),\n",
    "                html.Br(),\n",
    "                html.Div(id='test-data-upload-result0',style={'text-align': 'center'}),\n",
    "            ],\n",
    "            style={'text-align': 'center'}\n",
    "        )\n",
    "        \n",
    "        @app.callback(\n",
    "        Output('train-data-upload-result0', 'children'),\n",
    "        Input('current', 'children'),\n",
    "        )\n",
    "        \n",
    "        def store_data_train(current):\n",
    "            if self.data_frame is not None :\n",
    "                return  dash_table.DataTable(\n",
    "                        data=self.data_frame.to_dict('records'),\n",
    "                        columns=[{'name': col, 'id': col} for col in self.data_frame.columns],\n",
    "                        page_size=10,style_table={'overflowX': 'auto'})\n",
    "            else:\n",
    "                return html.H5(\"You haven't uploaded train data yet.\",style={'color': \"red\"})\n",
    "\n",
    "\n",
    "        @app.callback(\n",
    "        Output('test-data-upload-result0', 'children'),\n",
    "        Input('current', 'children'),\n",
    "        )\n",
    "        \n",
    "        def store_data_test(current):\n",
    "            if self.data_frame2 is not None :\n",
    "                return  dash_table.DataTable(\n",
    "                        data=self.data_frame2.to_dict('records'),\n",
    "                        columns=[{'name': col, 'id': col} for col in self.data_frame2.columns],\n",
    "                        page_size=10,style_table={'overflowX': 'auto'})\n",
    "            else:\n",
    "                return html.H5(\"You haven't uploaded test data yet.\",style={'color': \"red\"})\n",
    "\n",
    "\n",
    "# =======================================================================================================================\n",
    "\n",
    "        #第一頁 讀檔案\n",
    "        page1_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                html.H1(\"Data preparation\"),\n",
    "                html.Br(),\n",
    "                html.H3(\"Upload your data\"),\n",
    "                html.Br(),\n",
    "                #train data\n",
    "                dcc.Upload(\n",
    "                    id='upload-data-train',\n",
    "                    children=html.Div([\n",
    "                        'Train: Drag and Drop or ',\n",
    "                        html.A('Select Files')\n",
    "                    ]),\n",
    "                    style={\n",
    "                        'width': '100%',\n",
    "                        'height': '60px',\n",
    "                        'lineHeight': '60px',\n",
    "                        'borderWidth': '1px',\n",
    "                        'borderStyle': 'dashed',\n",
    "                        'borderRadius': '5px',\n",
    "                        'textAlign': 'center',\n",
    "                        'margin': '10px'\n",
    "                    },\n",
    "                    multiple=True\n",
    "                ),\n",
    "                \n",
    "                html.H5(id='train-data-upload-result',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "               \n",
    "                #test data\n",
    "                dcc.Upload(\n",
    "                    id='upload-data-test',\n",
    "                    children=html.Div([\n",
    "                        'Test: Drag and Drop or ',\n",
    "                        html.A('Select Files')\n",
    "                    ]),\n",
    "                    style={\n",
    "                        'width': '100%',\n",
    "                        'height': '60px',\n",
    "                        'lineHeight': '60px',\n",
    "                        'borderWidth': '1px',\n",
    "                        'borderStyle': 'dashed',\n",
    "                        'borderRadius': '5px',\n",
    "                        'textAlign': 'center',\n",
    "                        'margin': '10px'\n",
    "                    },\n",
    "                    multiple=True),\n",
    "                html.H5(id='test-data-upload-result',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                \n",
    "                #target chosen\n",
    "                html.H3('Choose a variable to be a target',style={'text-align': 'center'}),\n",
    "                dcc.Dropdown(id=\"column_target\", \n",
    "                                multi=False,\n",
    "                                style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div([html.Button('confirm', id='button0',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                          style={'textAlign': 'center', 'position': 'relative'}),\n",
    "                html.Br(),\n",
    "                html.H3(id='text',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "            ],\n",
    "            style={'text-align': 'center'}\n",
    "        )\n",
    "        \n",
    "        @app.callback(\n",
    "        Output('train-data-upload-result', 'children'),\n",
    "        Input('upload-data-train', 'contents'),\n",
    "        )\n",
    "        \n",
    "        def store_data_train(train_contents):\n",
    "            if train_contents is not None:\n",
    "                train_content_type, train_content_string = train_contents[0].split(',')\n",
    "                decoded = base64.b64decode(train_content_string)\n",
    "                self.data_frame= pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "                self.option_train=self.data_frame.columns\n",
    "                return  html.H5('Train data has been upload.',style={'text-align': 'center','color':'green'})\n",
    "            elif self.data_frame is not None:\n",
    "                return  html.H5('Train data exist! you can renew your data',style={'text-align': 'center','color':'green'})\n",
    "            else:\n",
    "                return \"Please Upload Train Data\"\n",
    "\n",
    "\n",
    "        @app.callback(\n",
    "        Output('test-data-upload-result', 'children'),\n",
    "        Input('upload-data-test', 'contents'),\n",
    "        )\n",
    "        \n",
    "        def store_data_test(test_contents):\n",
    "            if test_contents is not None:\n",
    "                test_content_type, test_content_string = test_contents[0].split(',')\n",
    "                decoded = base64.b64decode(test_content_string)\n",
    "                self.data_frame2 = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "                self.option_test=self.data_frame2.columns\n",
    "                return  html.H5('Test data has been upload.',style={'text-align': 'center','color':'green'})\n",
    "            elif self.data_frame2 is not None:\n",
    "                return  html.H5('Test data exist! you can renew your data',style={'text-align': 'center','color':'green'})\n",
    "            else:\n",
    "                return \"Please Upload Test Data\" \n",
    "        @app.callback(\n",
    "            Output(\"column_target\", \"options\"),\n",
    "            Input('train-data-upload-result', \"children\")\n",
    "        )\n",
    "        def get_options(useless0):\n",
    "            output = {}\n",
    "            if self.data_frame is not None:\n",
    "                dff = self.data_frame\n",
    "                output = dff.columns\n",
    "            return  output\n",
    "           \n",
    "        @app.callback(\n",
    "            Output(\"text\", \"children\"),\n",
    "            Input(\"column_target\", \"value\"),\n",
    "            Input(component_id='button0', component_property='n_clicks') \n",
    "        )  \n",
    "        def show(value,n_clicks):\n",
    "            if n_clicks:\n",
    "                self.target_column=value\n",
    "                return html.H5(f'the target you select is {self.target_column}')\n",
    "            else:\n",
    "                if self.target_column is not None:\n",
    "                    return html.H5(f'the target you select is {self.target_column}')\n",
    "                else:\n",
    "                    return html.H5(f\"you haven't choose a target\",style={'color': \"red\"})\n",
    "                \n",
    "\n",
    "        \n",
    "# =======================================================================================================================\n",
    "\n",
    "        #page3 EDA\n",
    "        page2_layout=([\n",
    "            html.Br(),\n",
    "            html.H1(\"Data EDA\",style={'text-align': 'center'}),\n",
    "            html.Br(),\n",
    "            dcc.RadioItems(id=\"EDA-radioitems\",\n",
    "                           options=[\"Train\", \"Test\"], value=\"Train\",\n",
    "                           labelStyle={'display': 'inline-block', 'margin-right': '10px'}),\n",
    "            html.Div([\n",
    "                html.Div(children=[\n",
    "                        html.H3(\"distribution visualization\",style={'text-align': 'center'}),\n",
    "                        html.Br(),\n",
    "                        html.H5(\"choose a column\",style={'text-align': 'center'}),\n",
    "                        dcc.Dropdown(id=\"slt_feat1\", \n",
    "                                    multi=False,\n",
    "                                    style={'text-align': 'center'}),\n",
    "                        html.Br(),\n",
    "                        html.Br(),\n",
    "                        dcc.Graph(id=\"Single_feat\"),\n",
    "                        html.Div(id=\"nullcounts\")], \n",
    "                        style={'width':'50%', 'padding':'1%'}),\n",
    "                html.Div(children=[\n",
    "                        html.H3(\"comparation of two variable\",style={'text-align': 'center'}),\n",
    "                        html.Br(),\n",
    "                        html.H5(\"choose your first variable\",style={'text-align': 'center'}),\n",
    "                        dcc.Dropdown(id=\"slt_feat2\", \n",
    "                                    multi=False,\n",
    "                                    style={'text-align': 'center'}),\n",
    "\n",
    "                        html.H5(\"choose your second variable\",style={'text-align': 'center'}),\n",
    "                        dcc.Dropdown(id=\"slt_feat3\", \n",
    "                                    multi=False, \n",
    "                                    style={'text-align': 'center'}),\n",
    "                        dcc.Graph(id=\"Double_feat\")], \n",
    "                        style={'width':'50%', 'padding':'1%'})\n",
    "            ], style={\n",
    "                    'display':'flex',\n",
    "                    'align-item':'center',\n",
    "                    'justify-content':'space-evenly',\n",
    "                    'flex-direction':'row' }),\n",
    "            \n",
    "            # Train test comparison\n",
    "            html.Div(children=[\n",
    "                html.Br(),\n",
    "                html.H3(id='useless',children='Train Test Comparison',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                dcc.Dropdown(id=\"train_test_dropdown\",\n",
    "                             multi=False,\n",
    "                             style={'text-align': 'center'})]),\n",
    "            html.Br(),\n",
    "            html.Div(children=[\n",
    "                html.Div([\n",
    "                    dcc.Graph(id=\"train_test_comparison\")],\n",
    "                    style={'width':'50%', 'padding':'1%'}),\n",
    "                html.Br(),\n",
    "                html.Div([\n",
    "                    dcc.Graph(id=\"train_test_comparison2\")],\n",
    "                    style={'width':'50%', 'padding':'1%'})\n",
    "            ], style={\n",
    "                    'display':'flex',\n",
    "                    'align-item':'center',\n",
    "                    'justify-content':'space-evenly',\n",
    "                    'flex-direction':'row' })\n",
    "         ])\n",
    "        \n",
    "\n",
    "        @app.callback(\n",
    "            Output(\"slt_feat1\", \"options\"),\n",
    "            Output(\"slt_feat2\", \"options\"),\n",
    "            Output('slt_feat3','options'),\n",
    "            Input(\"EDA-radioitems\", \"value\")\n",
    "        )\n",
    "        \n",
    "        def update_EDA_options(option):\n",
    "            output = [{\"label\": \"Ex1\", \"value\": 'None'}]\n",
    "            if option == \"Train\":\n",
    "                if self.data_frame is not None:\n",
    "                    output = self.data_frame.columns\n",
    "            else:\n",
    "                if self.data_frame2 is not None:\n",
    "                    output = self.data_frame2.columns\n",
    "            return output,output,output\n",
    "            \n",
    "        @app.callback(\n",
    "            Output(component_id='Single_feat', component_property='figure'),\n",
    "            Input(component_id='slt_feat1', component_property='value'),\n",
    "            Input(component_id=\"EDA-radioitems\", component_property=\"value\")\n",
    "        )    \n",
    "        #若有任何一個引數為None則回傳True\n",
    "        def update(feat1, tset):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True \n",
    "                return False\n",
    "            fig1 = self.placeholder_figure()\n",
    "            target = self.target_column\n",
    "            targetdf = None if (tset is None) else (self.data_frame if tset == 'Train' else self.data_frame2)\n",
    "            if not anyNone(targetdf, feat1) and feat1 in targetdf.columns: \n",
    "                # 類別型資料做 barplot\n",
    "                if (len(set(targetdf.loc[:,feat1]))<=4 or targetdf.dtypes[feat1] in [\"object\"]):\n",
    "                    counts = targetdf.loc[:,feat1].value_counts()\n",
    "                    fig1 = px.bar(counts,x=counts.index,y=counts.values,title=f'barplot',color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                # 數值型資料做 histogram\n",
    "                else:\n",
    "                    fig1 = px.histogram(targetdf, x=feat1, title=f'Histogram',color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                    fig1.update_traces(marker=dict(line=dict(color='rgb(100,100,100)', width=0.8)))\n",
    "                    \n",
    "            return fig1\n",
    "                    \n",
    "        @app.callback(\n",
    "            Output(component_id='Double_feat', component_property='figure'),\n",
    "            Input(component_id='slt_feat2', component_property='value'),\n",
    "            Input(component_id='slt_feat3', component_property='value'),\n",
    "            Input(component_id=\"EDA-radioitems\", component_property=\"value\")\n",
    "        )\n",
    "        \n",
    "        def update(feat2, feat3, tset):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True\n",
    "                return False\n",
    "            fig2 = self.placeholder_figure()\n",
    "            target = self.target_column\n",
    "            targetdf = None if anyNone(self.data_frame,self.data_frame2) else (self.data_frame if tset=='Train' else self.data_frame2)\n",
    "            if not anyNone(targetdf, feat2,feat3) and feat2 in targetdf.columns and feat3 in targetdf.columns: \n",
    "                # 數值對類別做 boxplot，數值對數值做 scatter 類別對類別做barplot\n",
    "                if ((len(set(targetdf.loc[:,feat2]))<=4 or targetdf.dtypes[feat2] in [\"object\"]) and len(set(targetdf.loc[:,feat3]))>4):\n",
    "                    fig2 = px.box(targetdf,x=feat2, y=feat3,title='box plot',\n",
    "                                  color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                elif (len(set(targetdf.loc[:,feat2]))>4 and (len(set(targetdf.loc[:,feat3]))<=4 or targetdf.dtypes[feat2] in [\"object\"])):\n",
    "                    fig2 = px.box(targetdf,x=feat2, y=feat3,title='box plot',\n",
    "                                  color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                elif (len(set(targetdf.loc[:,feat2]))<=4 and (len(set(targetdf.loc[:,feat3]))<=4)) or (targetdf.dtypes[feat2] in [\"object\"] and targetdf.dtypes[feat3] in [\"object\"]):\n",
    "                    fig2 = px.histogram(targetdf, x=feat2,color=feat3,barmode='group',color_discrete_sequence=['rgb(160, 198, 213)','rgb(160, 198, 184)','rgb(255,222,173)','rgb(188,143,143)'])\n",
    "                else:\n",
    "                    fig2 = px.scatter(targetdf, x=feat2, y=feat3, title=\"Scatter Plot\",\n",
    "                                      color_discrete_sequence=['rgb(160, 198, 213)'],\n",
    "                                      trendline='ols',\n",
    "                                      trendline_color_override='orange')\n",
    "            return fig2\n",
    "\n",
    "\n",
    "        @app.callback(\n",
    "        Output(\"train_test_dropdown\",'options'),\n",
    "        Input('useless','children'))\n",
    "        \n",
    "        def get_options(useless):\n",
    "            output = [{\"label\": \"Ex1\", \"value\": 'None'}]\n",
    "            if self.data_frame2 is not None:\n",
    "                output = self.data_frame2.columns\n",
    "            return output\n",
    "        \n",
    "        @app.callback(\n",
    "            Output('train_test_comparison','figure'),\n",
    "            Output('train_test_comparison2','figure'),\n",
    "            Input(\"train_test_dropdown\",'value')\n",
    "        )\n",
    "        def train_test_comparison(train_test_dropdown):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True\n",
    "                return False\n",
    "            fig10, fig11 = self.placeholder_figure(), self.placeholder_figure()\n",
    "            df_1 = self.data_frame\n",
    "            df_2 = self.data_frame2\n",
    "            if not anyNone(df_1,df_2,train_test_dropdown) and train_test_dropdown in df_2.columns: \n",
    "                x1 = df_1.loc[:,train_test_dropdown]\n",
    "                x2 = df_2.loc[:,train_test_dropdown]\n",
    "                df1 = pd.DataFrame({\"index\": x1.index, f\"{train_test_dropdown}\": x1, \"Type\": \"train\"})\n",
    "                df2 = pd.DataFrame({\"index\": x2.index+x1.shape[0], f\"{train_test_dropdown}\": x2, \"Type\": \"test\"})\n",
    "                df = pd.concat([df1, df2])\n",
    "                if len(set(df_1.loc[:,train_test_dropdown]))>4 and len(set(df_2.loc[:,train_test_dropdown]))>4:\n",
    "                    fig10 = px.scatter(df, x='index',y=f'{train_test_dropdown}',color='Type',color_discrete_sequence=['rgb(160, 198, 213)','rgb(160, 198, 184)'],title=f'trend of {train_test_dropdown} for train and test set')\n",
    "                    fig11=px.box(df,x='Type',y=f'{train_test_dropdown}',color_discrete_sequence=['rgb(160, 198, 213)','rgb(160, 198, 184)'],title=f'{train_test_dropdown} in train and test')\n",
    "                else :\n",
    "                    train_counts = x1.value_counts()\n",
    "                    test_counts = x2.value_counts()\n",
    "                    combined_counts = pd.concat([train_counts, test_counts], axis=1)\n",
    "                    combined_counts.columns = ['Train', 'Test']\n",
    "                    fig10 = px.bar(combined_counts, x=combined_counts.index, y=['Train', 'Test'], barmode='group',\n",
    "                                   color_discrete_sequence=['rgb(160, 198, 213)','rgb(160, 198, 184)'],title=f'count in train and test')\n",
    "                    fig10.update_layout(yaxis=dict(title='Counts'))\n",
    "            \n",
    "            return fig10,fig11\n",
    "           \n",
    "# =======================================================================================================================\n",
    "\n",
    "        page3_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                html.H1(\"Missing Value Imputing\",style={'text-align': 'center'}),\n",
    "                \n",
    "                #畫所有資料的缺失量(histogram)\n",
    "                \n",
    "                #train data\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.H3(\"Histogram of missing values in train data\",style={'text-align': 'center'}),\n",
    "                dcc.Graph(id=\"hist_missing\",style={'display': 'block'}),\n",
    "                html.Br(),\n",
    "                html.Div(id=\"nullpercent\",\n",
    "                         style={'font-size':'18px','display': 'block','text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                \n",
    "                #test data\n",
    "                html.Br(),\n",
    "                html.H3(\"Histogram of missing values in test data\",style={'text-align': 'center'}),\n",
    "                dcc.Graph(id=\"hist_missing2\",style={'display': 'block'}),\n",
    "                html.Br(),\n",
    "                html.Div(id=\"nullpercent2\",\n",
    "                         style={'font-size':'18px','display': 'block','text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "\n",
    "                html.H4(\"How to impute categorical variables (required)\",style={'text-align': 'left'}), \n",
    "                html.Br(),\n",
    "                dcc.Dropdown(id=\"dealwith_categ\", options=[{'label':'Drop NaN','value':'Drop NaN'},{'label':'Mode','value':'Mode'}], \n",
    "                             multi=False,\n",
    "                             value=None,\n",
    "                             style={'width': \"90%\"}),\n",
    "                \n",
    "                \n",
    "                html.Br(),\n",
    "                \n",
    "                #option\n",
    "                html.H4(\"How to impute numeric variables (required)\",style={'text-align': 'left'}), \n",
    "                html.Br(),\n",
    "                dcc.Dropdown(id=\"imputation\", options=[\n",
    "                                                       {'label':'Drop NaN','value':'Drop NaN'},\n",
    "                                                       {'label':'Mode','value':'Mode'},\n",
    "                                                       {'label':'Median','value':'Median'},\n",
    "                                                       {'label':'Mean','value':'Mean'},\n",
    "                                                       {'label':'KNN-3','value':'KNN-3'},\n",
    "                                                       {'label':'KNN-5','value':'KNN-5'}], \n",
    "                             multi=False,\n",
    "                             value=None, #預設值\n",
    "                             style={'width': \"70%\"}),\n",
    "                \n",
    "                html.Br(),\n",
    "                html.Div([html.Button('confirm', id='button1',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                      style={'textAlign': 'center', 'position': 'relative'}),\n",
    "                \n",
    "                #更新補值後資料\n",
    "                html.Br(),\n",
    "                html.H3(\"Now your data:\",style={'text-align': 'center'}), \n",
    "                html.Br(),\n",
    "                html.H5(\"Train data:\",style={'text-align': 'center'}), \n",
    "                html.Div(id=\"data_page\"),\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.H5(\"Test data:\",style={'text-align': 'center'}), \n",
    "                html.Div(id=\"data_page_test\")\n",
    "            ]\n",
    "        )\n",
    "                \n",
    "        @app.callback(\n",
    "            Output(component_id='hist_missing', component_property='figure'),\n",
    "            Output(component_id='nullpercent', component_property='children'), \n",
    "            Output(component_id='hist_missing2', component_property='figure'), \n",
    "            Output(component_id='nullpercent2', component_property='children'),  \n",
    "            Output(component_id='data_page', component_property='children'),\n",
    "            Output(component_id='data_page_test', component_property='children'),\n",
    "            Input(component_id='imputation', component_property='value'),\n",
    "            Input(component_id='dealwith_categ', component_property='value'),\n",
    "            Input(component_id='button1',component_property='n_clicks')\n",
    "        )\n",
    "\n",
    "        def update_plotp3(imputation,dealwith_categ,n_clicks):\n",
    "            fig5 = self.placeholder_figure()\n",
    "            nullper_text = ''\n",
    "            fig9 = self.placeholder_figure()\n",
    "            nullper_text2 = ''\n",
    "            table_train = html.H5(f\"you haven't upload train data\",style={'text-align': 'center','color': \"red\"})\n",
    "            table_test = html.H5(f\"you haven't upload test data\",style={'text-align': 'center','color': \"red\"})\n",
    "            if self.data_frame is not None and self.data_frame2 is not None:\n",
    "                missing_values = self.data_frame.isna().sum().sort_values(ascending=False)\n",
    "                missing_values2 = self.data_frame2.isna().sum().sort_values(ascending=False)\n",
    "                if missing_values.sum()==0 and missing_values2.sum()==0:\n",
    "                    table_train=dash_table.DataTable(data=self.data_frame.to_dict('records'),\n",
    "                                         page_size=10,style_table={'overflowX': 'auto'})\n",
    "                    table_test=dash_table.DataTable(data=self.data_frame2.to_dict('records'),\n",
    "                                         page_size=10,style_table={'overflowX': 'auto'})\n",
    "                else:\n",
    "                    fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                    fig5.update_traces(marker=dict(line=dict(color='black', width=0.5))) #加框線\n",
    "\n",
    "                    #回傳缺失值比例\n",
    "                    missing_per = 100*round(self.data_frame.isnull().sum().sum()/(self.data_frame.shape[0]*self.data_frame.shape[1]),3)\n",
    "                    nullper_text = f\"Percentage of missing values in train set: {missing_per} %\"\n",
    "\n",
    "                    \n",
    "                    fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "                    fig9.update_traces(marker=dict(line=dict(color='black', width=0.5))) #加框線\n",
    "\n",
    "                    #回傳缺失值比例\n",
    "                    missing_per2 = 100*round(self.data_frame2.isnull().sum().sum()/(self.data_frame2.shape[0]*self.data_frame2.shape[1]),3)\n",
    "                    nullper_text2 = f\"Percentage of missing values in test set: {missing_per2} %\"\n",
    "\n",
    "                    if n_clicks:\n",
    "                        #處理類別型資料的方式\n",
    "                        if dealwith_categ=='Mode':\n",
    "                            categ_list=[i for i in self.data_frame.columns if self.data_frame.dtypes[i] in ['object'] or len(set(self.data_frame.loc[:,i]))<=4]\n",
    "                            for feat in categ_list:\n",
    "                                arg = np.array(self.data_frame[feat])\n",
    "                                arg = arg.reshape([-1, 1])\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg)\n",
    "                                self.data_frame[feat] = imputed_data\n",
    "                            categ_list2=[i for i in self.data_frame2.columns if self.data_frame2.dtypes[i] in ['object'] or len(set(self.data_frame2.loc[:,i]))<=4]\n",
    "                            for feat in categ_list2:\n",
    "                                arg = np.array(self.data_frame2[feat])\n",
    "                                arg = arg.reshape([-1, 1])\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg)\n",
    "                                self.data_frame2[feat] = imputed_data\n",
    "                        elif dealwith_categ=='Drop NaN':\n",
    "                            categ_list=[i for i in self.data_frame.columns if self.data_frame.dtypes[i] in ['object'] or len(set(self.data_frame.loc[:,i]))<=4]\n",
    "                            self.data_frame=self.data_frame.dropna(subset=categ_list).reset_index(drop=True)\n",
    "                            self.data_frame2=self.data_frame2.dropna(subset=categ_list).reset_index(drop=True)\n",
    "\n",
    "                        if imputation=='Drop NaN':\n",
    "                            self.data_frame=self.data_frame.dropna().reset_index(drop=True)\n",
    "                            self.data_frame2=self.data_frame2.dropna().reset_index(drop=True)\n",
    "                            nullper_text = f\"Percentage of missing values in train set: 0 %\"\n",
    "                            nullper_text2 = f\"Percentage of missing values in test set: 0 %\"\n",
    "                            missing_values = self.data_frame.isna().sum()\n",
    "                            fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                            missing_values2 = self.data_frame2.isna().sum()\n",
    "                            fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "\n",
    "                        elif imputation == 'Mean':\n",
    "                            has_missing_values = self.data_frame.isna().any(axis=0)  #每個欄位有沒有缺失值(總欄位數個True或False)\n",
    "                            cols_with_missing_values = self.data_frame.columns[has_missing_values]  #取出哪些欄位有缺失值\n",
    "                            for feat in cols_with_missing_values:\n",
    "                                arg = np.array(self.data_frame[feat])  \n",
    "                                arg = arg.reshape([-1, 1])   \n",
    "\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg)\n",
    "                                self.data_frame[feat] = imputed_data\n",
    "\n",
    "                            has_missing_values2 = self.data_frame2.isna().any(axis=0)  \n",
    "                            cols_with_missing_values2 = self.data_frame2.columns[has_missing_values2] \n",
    "                            for feat in cols_with_missing_values2:\n",
    "                                arg = np.array(self.data_frame2[feat]) \n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame2[feat] = imputed_data\n",
    "                            nullper_text = f\"Percentage of missing values in train set: 0 %\"\n",
    "                            nullper_text2 = f\"Percentage of missing values in test set: 0 %\" \n",
    "                            missing_values = self.data_frame.isna().sum()\n",
    "                            fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                            missing_values2 = self.data_frame2.isna().sum()\n",
    "                            fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "\n",
    "                        elif imputation == 'Mode' : \n",
    "                            has_missing_values = self.data_frame.isna().any(axis=0)\n",
    "                            cols_with_missing_values = self.data_frame.columns[has_missing_values]\n",
    "                            for feat in cols_with_missing_values:\n",
    "                                arg = np.array(self.data_frame[feat])\n",
    "                                arg = arg.reshape([-1, 1])\n",
    "\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg)\n",
    "                                self.data_frame[feat] = imputed_data\n",
    "\n",
    "                            has_missing_values2 = self.data_frame2.isna().any(axis=0)  \n",
    "                            cols_with_missing_values2 = self.data_frame2.columns[has_missing_values2] \n",
    "                            for feat in cols_with_missing_values2:\n",
    "                                arg = np.array(self.data_frame2[feat]) \n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame2[feat] = imputed_data\n",
    "    \n",
    "                            nullper_text = f\"Percentage of missing values in train set: 0 %\"\n",
    "                            nullper_text2 = f\"Percentage of missing values in test set: 0 %\" \n",
    "                            missing_values = self.data_frame.isna().sum()\n",
    "                            fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                            missing_values2 = self.data_frame2.isna().sum()\n",
    "                            fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "\n",
    "\n",
    "                        elif imputation == 'Median':\n",
    "                            has_missing_values = self.data_frame.isna().any(axis=0)\n",
    "                            cols_with_missing_values = self.data_frame.columns[has_missing_values]\n",
    "                            for feat in cols_with_missing_values:\n",
    "                                arg = np.array(self.data_frame[feat])\n",
    "                                arg = arg.reshape([-1, 1])\n",
    "\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg)\n",
    "                                self.data_frame[feat] = imputed_data\n",
    "\n",
    "                            has_missing_values2 = self.data_frame2.isna().any(axis=0)  \n",
    "                            cols_with_missing_values2 = self.data_frame2.columns[has_missing_values2] \n",
    "                            for feat in cols_with_missing_values2:\n",
    "                                arg = np.array(self.data_frame2[feat]) \n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame2[feat] = imputed_data\n",
    "                            nullper_text = f\"Percentage of missing values in train set: 0 %\"\n",
    "                            nullper_text2 = f\"Percentage of missing values in test set: 0 %\"      \n",
    "                            missing_values = self.data_frame.isna().sum()\n",
    "                            fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                            missing_values2 = self.data_frame2.isna().sum()\n",
    "                            fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "\n",
    "                        elif imputation == \"KNN-3\":\n",
    "                            has_missing_values = self.data_frame.isna().any(axis=0)  #每個欄位有沒有缺失值(總欄位數個True或False)\n",
    "                            cols_with_missing_values = self.data_frame.columns[has_missing_values]  #取出哪些欄位有缺失值\n",
    "                            for feat in cols_with_missing_values:\n",
    "                                arg = np.array(self.data_frame[feat])\n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = KNNImputer(n_neighbors=3)\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame[feat] = imputed_data.reshape(-1)\n",
    "\n",
    "                            has_missing_values2 = self.data_frame2.isna().any(axis=0)  \n",
    "                            cols_with_missing_values2 = self.data_frame2.columns[has_missing_values2] \n",
    "                            for feat in cols_with_missing_values2:\n",
    "                                arg = np.array(self.data_frame2[feat]) \n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = KNNImputer(n_neighbors=3)\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame2[feat] = imputed_data.reshape(-1)\n",
    "                            \n",
    "                            nullper_text = f\"Percentage of missing values in train set: 0 %\"\n",
    "                            nullper_text2 = f\"Percentage of missing values in test set: 0 %\"    \n",
    "                            missing_values = self.data_frame.isna().sum()\n",
    "                            fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                            missing_values2 = self.data_frame2.isna().sum()\n",
    "                            fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "\n",
    "                        elif imputation == \"KNN-5\":\n",
    "                            has_missing_values = self.data_frame.isna().any(axis=0)  #每個欄位有沒有缺失值(總欄位數個True或False)\n",
    "                            cols_with_missing_values = self.data_frame.columns[has_missing_values]  #取出哪些欄位有缺失值\n",
    "                            for feat in cols_with_missing_values:\n",
    "                                arg = np.array(self.data_frame[feat])\n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = KNNImputer(n_neighbors=5)\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame[feat] = imputed_data.reshape(-1)\n",
    "\n",
    "                            has_missing_values2 = self.data_frame2.isna().any(axis=0)  \n",
    "                            cols_with_missing_values2 = self.data_frame2.columns[has_missing_values2] \n",
    "                            for feat in cols_with_missing_values2:\n",
    "                                arg = np.array(self.data_frame2[feat]) \n",
    "                                arg = arg.reshape([-1, 1])  \n",
    "\n",
    "                                imr = KNNImputer(n_neighbors=5)\n",
    "                                imr = imr.fit(arg)\n",
    "                                imputed_data = imr.transform(arg) \n",
    "                                self.data_frame2[feat] = imputed_data.reshape(-1)\n",
    "                            \n",
    "                            nullper_text = f\"Percentage of missing values in train set: 0 %\"\n",
    "                            nullper_text2 = f\"Percentage of missing values in test set: 0 %\"\n",
    "                            missing_values = self.data_frame.isna().sum()\n",
    "                            fig5 = px.histogram(x=missing_values.index, y=missing_values.values,color_discrete_sequence=['rgb(160, 198, 213)'])\n",
    "                            missing_values2 = self.data_frame2.isna().sum()\n",
    "                            fig9 = px.histogram(x=missing_values2.index, y=missing_values2.values,color_discrete_sequence=['rgb(160, 198, 184)'])\n",
    "\n",
    "                        table_train = dash_table.DataTable(data=self.data_frame.to_dict('records'),\n",
    "                                         page_size=10,style_table={'overflowX': 'auto'})\n",
    "                        table_test = dash_table.DataTable(data=self.data_frame2.to_dict('records'),\n",
    "                                         page_size=10,style_table={'overflowX': 'auto'})\n",
    "                    else:\n",
    "                        table_train=dash_table.DataTable(data=self.data_frame.to_dict('records'),\n",
    "                                         page_size=10,style_table={'overflowX': 'auto'})\n",
    "                        table_test=dash_table.DataTable(data=self.data_frame2.to_dict('records'),\n",
    "                                         page_size=10,style_table={'overflowX': 'auto'})\n",
    "                        \n",
    "            return fig5,nullper_text,fig9,nullper_text2,table_train,table_test\n",
    "            \n",
    "\n",
    "# =======================================================================================================================\n",
    "        \n",
    "        #encoding\n",
    "        page4_layout=html.Div(\n",
    "        children=[\n",
    "            html.Br(),\n",
    "            html.H1(children=\"Feature Engineering\",style={'text-align': 'center'}),\n",
    "            html.Hr(),\n",
    "            html.Br(),\n",
    "            html.H3(id='useless2',children=\"Encode Categorical Variables\",style={'text-align': 'center'}),\n",
    "            html.Hr(),\n",
    "            html.Br(),\n",
    "            html.Div(id='warn_encode',style={'text-align': 'center'}),\n",
    "            html.Br(),\n",
    "            dcc.Checklist(id=\"columns\", \n",
    "                            inline=True,\n",
    "                            labelStyle={\"display\": \"inline-block\", \"margin-right\": \"12px\"},\n",
    "                            style={'text-align': 'center'}),\n",
    "            html.Br(),\n",
    "            html.H5('Encoding Options',style={'text-align': 'center'}),\n",
    "            dcc.Dropdown(id=\"encode_options\",\n",
    "                            options=['one-hot encoding','target encoding','label encoding'],\n",
    "                            multi=False,\n",
    "                            value=[],\n",
    "                            ),\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            html.Div([html.Button('confirm', id='button',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                      style={'textAlign': 'center', 'position': 'relative'}),\n",
    "            html.Div(id='false',style={'text-align': 'center'}),\n",
    "            html.Br(),\n",
    "            html.Div(id='success',style={'text-align': 'center'}),\n",
    "        ])\n",
    "        \n",
    "        @app.callback(\n",
    "            Output(\"warn_encode\", \"children\"),\n",
    "            Output(\"columns\", \"options\"),\n",
    "            Input(\"useless2\", \"children\")\n",
    "        )\n",
    "        \n",
    "        def get_options(useless2):\n",
    "            output2 = {}\n",
    "            warn=html.H5('You have not upload your data',style={'color': \"red\"})\n",
    "            if self.data_frame is not None:\n",
    "                dff = self.data_frame\n",
    "                output2 = [i for i in dff.columns if dff.dtypes[i] in ['object']]\n",
    "                if output2==[]:\n",
    "                    warn=html.H5('No categorical variable need to encode !!',style={'color': \"red\"})\n",
    "                    return warn,output2\n",
    "                else:\n",
    "                    warn=html.H5('These are catagorical variables in your data !!')\n",
    "                    return warn,output2\n",
    "            else:\n",
    "                return warn,output2\n",
    "        \n",
    "        @app.callback(\n",
    "        [Output(component_id='success',component_property='children'),            \n",
    "        Output(component_id='false',component_property='children')], \n",
    "        [Input(component_id='columns',component_property='value'),\n",
    "        Input(component_id='encode_options',component_property='value'),\n",
    "        Input(component_id='button', component_property='n_clicks')]\n",
    "        )\n",
    "        \n",
    "        def encode(column,encode_options,n_clicks):\n",
    "            false = ''\n",
    "            result={}\n",
    "            if n_clicks:\n",
    "                if self.data_frame is not None and self.data_frame2 is not None:\n",
    "                    target=self.target_column\n",
    "                    if encode_options == 'one-hot encoding':\n",
    "                        for col in column:\n",
    "                            self.data_frame = pd.get_dummies(self.data_frame, columns=[col])\n",
    "                            self.data_frame2 = pd.get_dummies(self.data_frame2, columns=[col])\n",
    "\n",
    "\n",
    "                    elif encode_options == 'target encoding':\n",
    "                        enc = TargetEncoder(cols=column).fit(self.data_frame.drop(columns=target), self.data_frame.loc[:,target])\n",
    "                        # transform the datasets\n",
    "                        encode_data = enc.transform(self.data_frame.drop(columns=target))\n",
    "                        encode_data2 = enc.transform(self.data_frame2)\n",
    "                        self.data_frame = pd.concat([encode_data,self.data_frame.loc[:,self.target_column]],axis=1)\n",
    "                        self.data_frame2 = encode_data2\n",
    "\n",
    "\n",
    "                    elif encode_options == 'label encoding':\n",
    "                        #LabelEncoder\n",
    "                        for col in column:\n",
    "                            labelencoder = LabelEncoder()\n",
    "                            self.data_frame[col] = labelencoder.fit_transform(self.data_frame[col])\n",
    "                            self.data_frame2[col] = labelencoder.transform(self.data_frame2[col])\n",
    "                    \n",
    "                    result=html.H5('success',style={'text-align': 'center','color':'green'})\n",
    "                else:\n",
    "                    false=html.H5('This column is a numeric variable.',style={'color': \"red\"})\n",
    "                \n",
    "            return result,false\n",
    "# =======================================================================================================================\n",
    "        \n",
    "    #standardization\n",
    "        page5_layout=html.Div(\n",
    "        children=[\n",
    "            html.Br(),\n",
    "            html.H1(children=\"Feature Engineering\",style={'text-align': 'center'}),\n",
    "            html.Br(),\n",
    "            html.H3(\"Standardization and Normalization\",style={'text-align': 'center'}),\n",
    "            html.Hr(),\n",
    "            html.Br(),\n",
    "            html.H5('You can choose one method to shape your data (optional)',style={'text-align': 'center'}),\n",
    "            dcc.Dropdown(id=\"std-nor\",\n",
    "                            options=['No','Standardization','Normalization'],\n",
    "                            multi=False,\n",
    "                            value='No',\n",
    "                            ),\n",
    "            html.Br(),\n",
    "            html.Div([html.Button('confirm', id='button_std',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                      style={'textAlign': 'center', 'position': 'relative'}),\n",
    "            html.Br(),\n",
    "            html.Div(id='success_std',style={'text-align': 'center'}),\n",
    "        ])\n",
    "        @app.callback(\n",
    "        Output(component_id='success_std',component_property='children'),            \n",
    "        [Input(component_id='std-nor',component_property='value'),\n",
    "        Input(component_id='button_std', component_property='n_clicks')])\n",
    "        \n",
    "        def std(std_nor,n_clicks):\n",
    "            result={}\n",
    "            if n_clicks:   \n",
    "                    if std_nor=='Standardization':\n",
    "                        data=self.data_frame\n",
    "                        data1=self.data_frame2\n",
    "                        \n",
    "                        for i in self.data_frame.columns:\n",
    "                            if len(set(self.data_frame.loc[:,i]))<4 or self.data_frame.dtypes[i] in ['object'] or i=='id' or i==self.target_column:\n",
    "                                data = data.drop([i], axis = 1)\n",
    "                        for i in self.data_frame2.columns:\n",
    "                            if len(set(self.data_frame2.loc[:,i]))<4 or self.data_frame2.dtypes[i] in ['object'] or i=='id'or i==self.target_column:\n",
    "                                data1 = data1.drop([i], axis = 1)\n",
    "                                \n",
    "                        columns=data.columns\n",
    "                        columns1=data1.columns\n",
    "                        \n",
    "                        data = preprocessing.scale(data)\n",
    "                        data1 = preprocessing.scale(data1)\n",
    "                        \n",
    "                        data = pd.DataFrame(data)\n",
    "                        data1 = pd.DataFrame(data1)\n",
    "                        \n",
    "                        data.columns=columns\n",
    "                        data1.columns=columns1\n",
    "\n",
    "                        for i in self.data_frame.columns:\n",
    "                            if i in data.columns:\n",
    "                                self.data_frame.loc[:,i]=data.loc[:,i]\n",
    "                        for j in self.data_frame2.columns:\n",
    "                            if j in data1.columns:\n",
    "                                self.data_frame2.loc[:,j]=data1.loc[:,j]\n",
    "                        result=html.H5('success',style={'text-align': 'center','color':'green'}) \n",
    "                       \n",
    "                    elif std_nor=='Normalization':\n",
    "                        data=self.data_frame\n",
    "                        data1=self.data_frame2\n",
    "                        \n",
    "                        for i in self.data_frame.columns:\n",
    "                            if len(set(self.data_frame.loc[:,i]))<4 or self.data_frame.dtypes[i] in ['object'] or i=='id' or i==self.target_column:\n",
    "                                data = data.drop([i], axis = 1)\n",
    "                        for i in self.data_frame2.columns:\n",
    "                            if len(set(self.data_frame2.loc[:,i]))<4 or self.data_frame2.dtypes[i] in ['object'] or i=='id' or i==self.target_column:\n",
    "                                data1 = data1.drop([i], axis = 1)\n",
    "                        \n",
    "                        columns=data.columns\n",
    "                        columns1=data1.columns\n",
    "                        data=preprocessing.normalize(data)\n",
    "                        data1=preprocessing.normalize(data1)\n",
    "\n",
    "                        data = pd.DataFrame(data)\n",
    "                        data1 = pd.DataFrame(data1)\n",
    "                        \n",
    "                        data.columns=columns\n",
    "                        data1.columns=columns1\n",
    "\n",
    "                        for i in self.data_frame.columns:\n",
    "                            if i in data.columns:\n",
    "                                self.data_frame.loc[:,i]=data.loc[:,i]\n",
    "                        for j in self.data_frame2.columns:\n",
    "                            if j in data1.columns:\n",
    "                                self.data_frame2.loc[:,j]=data1.loc[:,j]\n",
    "                        result=html.H5('success',style={'text-align': 'center','color':'green'})       \n",
    "            return result\n",
    "            \n",
    "# =======================================================================================================================\n",
    "\n",
    "        page6_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                html.H2(\"Introdution of methods for feature selection.\"),\n",
    "                html.Br(), \n",
    "                html.H4(\"Filter methods\"),\n",
    "                html.Br(),\n",
    "                html.H5(\"Filter methods evaluate the features independently of the model,\\\n",
    "                        using statistical tests or correlation measures to determine their relevance.\\\n",
    "                        They are computationally efficient and can handle high-dimensional datasets,\\\n",
    "                        but they may overlook interactions between features.\",style={'text-align': 'left'}),\n",
    "                html.Br(),\n",
    "                html.H4(\"Wrapper methods\"),\n",
    "                html.Br(),\n",
    "                html.H5(\"Wrapper methods evaluate subsets of features by training and testing a \\\n",
    "                        model with each subset, selecting the subset that performs the best. \\\n",
    "                        They can capture interactions between features but are computationally \\\n",
    "                        intensive and may overfit the data\",style={'text-align': 'left'}),\n",
    "                html.Br(),\n",
    "                html.H4(\"Embedded methods\"),\n",
    "                html.Br(),\n",
    "                html.H5(\"Embedded methods incorporate feature selection into the model training process,\\\n",
    "                        selecting the most relevant features during model training. \\\n",
    "                        They are computationally efficient and can capture interactions between features,\\\n",
    "                        but may not perform as well as wrapper methods on some datasets\",style={'text-align': 'left'}),\n",
    "                html.Br()\n",
    "                \n",
    "            ],\n",
    "            style={'text-align': 'center','width':'90%'}\n",
    "        )\n",
    "        \n",
    "# =======================================================================================================================        \n",
    "        \n",
    "        #filter method\n",
    "        page7_layout = html.Div(\n",
    "            children=[\n",
    "                #特徵篩選\n",
    "                html.Br(),\n",
    "                html.H1(id='useless3',children=\"Feature Selection by Correlation\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.H3(id='target-chosen',style={'text-align': 'left'}),\n",
    "                html.Br(),\n",
    "                html.H3(\"threshold for features\",style={'text-align': 'left'}),\n",
    "                html.H5(\"if the correlation of dependent variables are greater than this value, the less effective features would be droped.\",\n",
    "                         style={'text-align': 'left'}),\n",
    "                \n",
    "                dcc.Dropdown(id=\"threshold_for_features\",\n",
    "                            options=[{'label':str(num),'value':num} \\\n",
    "                                      for num in [round(x, 2) for x in list(np.arange(0.05, 1.00, 0.05))]],\n",
    "                            multi=False,\n",
    "                            value=0.95,\n",
    "                            style={'width':\"70%\"}),\n",
    "                html.Br(),\n",
    "                html.H3(\"threshold for target\",style={'text-align': 'left'}),\n",
    "                html.H5(\"show the correlation of dependent and independent variables if the values are greater than this value.\",\n",
    "                         style={'text-align': 'left'}),\n",
    "                dcc.Dropdown(id=\"threshold_for_target\",\n",
    "                             options=[{'label':str(num),'value':num} \\\n",
    "                                      for num in [round(x, 2) for x in list(np.arange(0.05, 1.00, 0.05))]],\n",
    "                            multi=False,\n",
    "                            value=0.6,\n",
    "                            style={'width':\"70%\"}),\n",
    "                dcc.Graph(id=\"selectheatmap\",style={'display': 'block'}),\n",
    "                html.H3('confirm if you want to use these feature',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div([html.Button('confirm', id='button-filter',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                          style={'textAlign': 'center', 'position': 'relative'}),\n",
    "                html.Br(),\n",
    "                html.Div(id='result_filter'),\n",
    "                html.Br()\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        @app.callback(\n",
    "            Output(component_id='target-chosen', component_property='children'),\n",
    "            Input(component_id='useless3', component_property='children'),\n",
    "        )\n",
    "        def target(useless3):\n",
    "            return html.H3(f'The target you select before : {self.target_column}')\n",
    "        \n",
    "        @app.callback(\n",
    "            Output(component_id='selectheatmap', component_property='figure'),\n",
    "            Output(component_id='result_filter', component_property='children'),\n",
    "            Input(component_id='threshold_for_target', component_property='value'),\n",
    "            Input(component_id='threshold_for_features', component_property='value'),\n",
    "            Input(component_id='button-filter', component_property='n_clicks')\n",
    "        )\n",
    "\n",
    "        def update_plotp4(threshold_for_target,threshold_for_features,n_clicks):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True \n",
    "                return False\n",
    "            #defalt\n",
    "            fig4 = self.placeholder_figure()\n",
    "            df_1 = self.data_frame\n",
    "            result={}\n",
    "            if not anyNone(df_1,threshold_for_target,threshold_for_features): \n",
    "                target=self.target_column\n",
    "                target_corr = df_1.corr()[target]\n",
    "                col_select=[]\n",
    "                \n",
    "                #找出跟target相關性高的column\n",
    "                for i,v in zip(target_corr.index,target_corr.values):\n",
    "                    if v > threshold_for_target:\n",
    "                        col_select.append(i)\n",
    "                        \n",
    "                #用這些column做一個新的data\n",
    "                select_data = df_1.loc[:,col_select]\n",
    "                no_target_select_data = select_data.drop(columns=target,axis=1) \n",
    "                high_correlation=[]\n",
    "                last=[i for i in select_data.columns]\n",
    "                for col in no_target_select_data.corr():\n",
    "                    high_correlation.append(col)\n",
    "                    for index,value in zip(no_target_select_data.corr()[col].index,no_target_select_data.corr()[col].values): \n",
    "                        if abs(value) > threshold_for_features and value!=1:\n",
    "                            high_correlation.append(index)\n",
    "                    data_temperate = df_1.loc[:,high_correlation]\n",
    "                    a=[data_temperate[i].corr(df_1.loc[:,target]) for i in data_temperate]\n",
    "                    b=[i for i in data_temperate]\n",
    "                    for num in range(len(a)):\n",
    "                        if a[num]==max(a):\n",
    "                            del b[num]\n",
    "                            for i in b:\n",
    "                                if i in last:\n",
    "                                    last.remove(i)\n",
    "                    high_correlation=[]\n",
    "                data=df_1.loc[:,last]\n",
    "                \n",
    "                if n_clicks:\n",
    "                    self.data_frame=df_1.loc[:,last]\n",
    "                    last.remove(target)\n",
    "                    self.data_frame2=self.data_frame2.loc[:,last]\n",
    "                    result=html.H5('success',style={'text-align': 'center','color':'green'})\n",
    "                \n",
    "                correlation=round(data.corr(),2)\n",
    "                x = list(correlation.index)\n",
    "                y = list(correlation.columns)\n",
    "                z = np.array(correlation)\n",
    "\n",
    "                fig4 = ff.create_annotated_heatmap(z, x = x, y = y , annotation_text = np.around(z, decimals=2),\n",
    "                                                   hoverinfo='z',colorbar_thickness=30, colorbar_ticklen=3,\n",
    "                                                   colorscale=[[0.0, 'rgb(221, 239, 232)'], [0.5, 'rgb(159, 208, 200)'], [1.0, 'rgb(82, 133, 109)']])\n",
    "                fig4.update_layout(title_text='<b>Correlation Matrix (cont. features)<b>',\n",
    "                    title_x=0.3,titlefont={'size': 24}, xaxis_showgrid=False, xaxis={'side': 'bottom'},\n",
    "                    yaxis_showgrid=False, yaxis_autorange='reversed', paper_bgcolor=None,)\n",
    "                \n",
    "            return fig4,result \n",
    "            \n",
    "            \n",
    "# =======================================================================================================================\n",
    "\n",
    "        page8_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                \n",
    "                #竭盡式特徵選取法\n",
    "                html.H1(id='uselesswrapper',children=\"Feature Selection by Exhaustive Feature Selector\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div(id=\"warning\",style={'color': \"rgb(220, 121, 106)\",\"font-size\": \"22px\"}),\n",
    "\n",
    "                #勾選框可以先篩掉確定不要的特徵(選要的)\n",
    "                html.H3(\"Select the features to be included in the wrapper method:\",style={'text-align': 'center'}),\n",
    "                dcc.Checklist(id=\"option_for_wrapper\",\n",
    "                    labelStyle={\"display\": \"inline-block\", \"margin-right\": \"12px\"},\n",
    "                    inline=True,\n",
    "                    style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                \n",
    "                html.H3(\"Minimum number of features:\",style={'text-align': 'left'}),\n",
    "                dcc.Dropdown(id=\"min_f\",\n",
    "                            \n",
    "                            multi=False,\n",
    "                            style={'width':\"70%\"}),\n",
    "                html.Br(),\n",
    "                html.H3(\"Maximum number of features:\",style={'text-align': 'left'}),\n",
    "                dcc.Dropdown(id=\"max_f\",\n",
    "                            multi=False,\n",
    "                            style={'width':\"70%\"}),\n",
    "                html.Br(),\n",
    "                \n",
    "                #等使用者調整好所有項目再開始update(讓他按按鈕)\n",
    "                html.Div([  html.Button('Ready!', id='update-button', n_clicks=0,\n",
    "                            style={'background-color': 'rgb(190, 223, 210)','font-size': '16px'})],\n",
    "                            style={'text-align': 'center'}),\n",
    "\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.H3(\"Feature selected by EFS :\",style={'text-align': 'center'}),\n",
    "                dbc.Spinner(html.Div(id=\"efs_result\",style={'text-align': 'center'}),color=\"primary\"),\n",
    "                html.Br(),\n",
    "                html.H3('confirm if you want to use these feature',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div([  html.Button('confirm!', id='decide-button', n_clicks=0,\n",
    "                            style={'background-color': 'rgb(190, 223, 210)','font-size': '16px'})],\n",
    "                            style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.H3(id=\"confirm_result\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                ]\n",
    "        )\n",
    "        \n",
    "        @app.callback(\n",
    "            Output(\"min_f\", \"options\"),\n",
    "            Output(\"max_f\", \"options\"),\n",
    "            Output(\"option_for_wrapper\", \"options\"),\n",
    "            Input(\"uselesswrapper\", \"children\")\n",
    "        )\n",
    "        def get_options(useless):\n",
    "            if self.data_frame2 is not None:\n",
    "                dff = self.data_frame2\n",
    "                output = ['Select All']+list(dff.columns)+['Deselect All']\n",
    "                return  list(range(1,len(dff.columns))),list(range(1,len(dff.columns))),output\n",
    "            else:\n",
    "                return  [],[],{}\n",
    "            \n",
    "        @app.callback(\n",
    "        Output(\"option_for_wrapper\", \"value\"),\n",
    "        Input(\"option_for_wrapper\", \"options\"),\n",
    "        Input(\"option_for_wrapper\", \"value\")\n",
    "        )\n",
    "        def select_all_options(options, value):\n",
    "            if options is None:\n",
    "                return []\n",
    "            if value is None:\n",
    "                return [option for option in options if option != \"Deselect All\"]\n",
    "            elif \"Deselect All\" in value:\n",
    "                return []\n",
    "            elif \"Select All\" in value:\n",
    "                return [option for option in options if option != \"Deselect All\"]\n",
    "            else:\n",
    "                return value\n",
    "    \n",
    "        @app.callback(\n",
    "            Output(component_id='warning', component_property='children'),\n",
    "            Output(component_id='efs_result', component_property='children'),\n",
    "            Output(component_id='confirm_result', component_property='children'),\n",
    "            Input(component_id='option_for_wrapper', component_property='value'),\n",
    "            Input(component_id='min_f', component_property='value'),\n",
    "            Input(component_id='max_f', component_property='value'),\n",
    "            Input(component_id='update-button', component_property='n_clicks'),\n",
    "            Input(component_id='decide-button', component_property='n_clicks'),\n",
    "        )\n",
    "\n",
    "        def update_plotp5(wanted,min_f,max_f,n_clicks,n_clicks_decide):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True\n",
    "            warn = {}\n",
    "            result = {}\n",
    "            confirm_result = {}\n",
    "            targetdf = None if (self.data_frame is None) else (self.data_frame)\n",
    "            target = None if (self.target_column is None) else (self.target_column)\n",
    "            if targetdf is None : \n",
    "                warn = html.H5(f\"You haven't upload train and test data\",style={'text-align': 'center','color':'red'})\n",
    "            if not anyNone(targetdf,target,wanted,min_f,max_f) and target in targetdf.columns:  \n",
    "                missing_values = targetdf.isna().any().any()\n",
    "                if missing_values:\n",
    "                    warn = \"Please go to 'Missing Value Imputing' to fill in missing values first!\"\n",
    "                else:\n",
    "                    warn=''\n",
    "                    if not isinstance(min_f, int) or not isinstance(max_f, int) or len(wanted) == 0:\n",
    "                        result='Please check once again that you have set all the parameters.'\n",
    "                    elif n_clicks: \n",
    "                        num_features = len(wanted)\n",
    "                        if  min_f > max_f :\n",
    "                            result = \"The maximum number of features should be greater than or equal to the minimum one.\"\n",
    "                        elif num_features < max_f :\n",
    "                            result = \"Please select more than {} features\".format(max_f)\n",
    "                        else:\n",
    "                            if 'Select All' in wanted:\n",
    "                                    x = self.data_frame.drop(columns=target) #全部\n",
    "                                    y = self.data_frame.loc[:,target]\n",
    "                                    selector = ExhaustiveFeatureSelector(\n",
    "                                        LinearRegression(), \n",
    "                                        min_features=min_f,\n",
    "                                        max_features=max_f,\n",
    "                                        scoring='neg_mean_squared_error',\n",
    "                                        print_progress=True,cv=5)\n",
    "\n",
    "                                    selector = selector.fit(x, y)\n",
    "\n",
    "                                    result_list = selector.best_feature_names_\n",
    "                                    result = ' / '.join(result_list)\n",
    "                                    if n_clicks_decide:\n",
    "                                        self.data_frame=self.data_frame.loc[:,list(result_list)+[target]]\n",
    "                                        self.data_frame2=self.data_frame2.loc[:,result_list]\n",
    "                                        confirm_result = html.H5('success',style={'text-align': 'center','color':'green'})\n",
    "                            elif 'Deselect All' in wanted:\n",
    "                                result = 'Please at least choose one feature.'\n",
    "                            else:\n",
    "                                x = self.data_frame.loc[:,wanted] #取出想要的欄位\n",
    "                                y = self.data_frame.loc[:,target]\n",
    "\n",
    "                                selector = ExhaustiveFeatureSelector(\n",
    "                                    LinearRegression(), \n",
    "                                    min_features=min_f,\n",
    "                                    max_features=max_f,\n",
    "                                    scoring='neg_mean_squared_error',\n",
    "                                    print_progress=True,cv=5)\n",
    "\n",
    "                                selector = selector.fit(x, y)\n",
    "\n",
    "                                result_list = selector.best_feature_names_\n",
    "                                result = ' / '.join(result_list)\n",
    "                                if n_clicks_decide:\n",
    "                                    self.data_frame=self.data_frame.loc[:,list(result_list)+[target]]\n",
    "                                    self.data_frame2=self.data_frame2.loc[:,result_list]\n",
    "                                    confirm_result = html.H5('success',style={'text-align': 'center','color':'green'})\n",
    "                    else:\n",
    "                        result = \"Click the Ready button to let me know that you have set the parameters.\"\n",
    "            return warn, result, confirm_result\n",
    "            \n",
    "# ======================================================================================================================= \n",
    "            \n",
    "        page9_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                html.H1(children=\"Embedded Methods\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.H4('Which method do you want to apply?',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                \n",
    "                html.Div([dcc.Dropdown(id=\"method_for_emb\",\n",
    "                            options=[{'label':'Lasso','value':'Lasso'}, \n",
    "                                     {'label':'Ridge','value':'Ridge'},\n",
    "                                     {'label':'Elastic nets','value':'Elastic nets'},\n",
    "                                     {'label':'Tree-base','value':'Tree-base'}],\n",
    "                            multi=False,value='Lasso',style={'width':\"75%\"})],style={'display': 'flex', 'justify-content': 'center', 'align-items': 'center','margin-left': '13%'}),\n",
    "                \n",
    "                html.Br(),\n",
    "                #結果\n",
    "                html.Br(),\n",
    "                html.Div(id=\"illustration_for_restrict\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                \n",
    "                html.Div([dcc.Dropdown(id=\"display_restrict\",multi=False,\n",
    "                                       style={'width':\"75%\"})],style={'display': 'flex', 'justify-content': 'center', 'align-items': 'center','margin-left': '13%'}),\n",
    "                \n",
    "                html.Br(),\n",
    "                dbc.Spinner(html.Div(id='output_embresult', style={'overflow':'auto','width':\"50%\",'text-align': 'center'}),color=\"primary\"),\n",
    "                html.Br(),\n",
    "                html.H3('confirm if you want to use these feature',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div([  html.Button('confirm!', id='decide', n_clicks=0,\n",
    "                            style={'background-color': 'rgb(190, 223, 210)','font-size': '16px'})],\n",
    "                            style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.H3(id=\"confirm_\",style={'text-align': 'center','color':'green'}),\n",
    "                html.Br()\n",
    "                ],\n",
    "            style={'text-align': 'left'}      \n",
    "        )\n",
    "        \n",
    "        \n",
    "        @app.callback(\n",
    "            Output(\"illustration_for_restrict\", \"children\"),\n",
    "            Input(\"method_for_emb\", \"value\")\n",
    "        )\n",
    "        \n",
    "        def update_options(method_for_emb):\n",
    "            illustration_for_restrict = html.H5('you have not upload your data.',style={'color':'red'})\n",
    "            targetdf = None if (self.data_frame is None) else (self.data_frame)\n",
    "            if targetdf is not None:\n",
    "                if method_for_emb =='Lasso':\n",
    "                    illustration_for_restrict = html.H4('Do you want to remove features with coefficient equal to 0?')\n",
    "                else:\n",
    "                    illustration_for_restrict = html.H4('What is the threshold for the coefficient values \\\n",
    "                    below which you would like to exclude features from the table?')\n",
    "            return illustration_for_restrict\n",
    "        \n",
    "        @app.callback(\n",
    "            Output('display_restrict','options'),\n",
    "            Input(\"method_for_emb\", \"value\")\n",
    "        )\n",
    "        \n",
    "        def update_no_target(method_for_emb):\n",
    "            options=[{\"label\": 'select', \"value\": 'select'}]\n",
    "            targetdf = None if (self.data_frame is None) else (self.data_frame)\n",
    "            if targetdf is not None:\n",
    "                if method_for_emb =='Lasso':\n",
    "                    options = [{'label':'Yes','value':'Yes'}, \n",
    "                             {'label':'No','value':'No'}]\n",
    "                else:\n",
    "                    options=[{'label':str(num),'value':num} \\\n",
    "                                       for num in [round(x, 3) for x in list(np.arange(0.01, 0.5, 0.01))]]\n",
    "            return options\n",
    "        \n",
    "        @app.callback(\n",
    "        Output(component_id='output_embresult', component_property='children'),\n",
    "        Output(component_id='confirm_', component_property='children'),\n",
    "        Input(component_id='method_for_emb', component_property='value'),\n",
    "        Input(component_id='display_restrict', component_property='value'),\n",
    "        Input(component_id='decide', component_property='n_clicks')\n",
    "            \n",
    "        )\n",
    "\n",
    "        def update_plotp7(method_for_emb,display_restrict,n_clicks):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True\n",
    "            # default value\n",
    "            output_embresult = None \n",
    "            confirm_ = {}\n",
    "            target=self.target_column\n",
    "            targetdf = None if (self.data_frame  is None) else (self.data_frame )\n",
    "            if not anyNone(method_for_emb,display_restrict) and display_restrict != 'select' :\n",
    "                missing_values = targetdf.isna().any().any()\n",
    "                feature_names = self.data_frame2.columns.tolist()\n",
    "                if missing_values:\n",
    "                    output_embresult = None\n",
    "                else:\n",
    "                    y = targetdf.loc[:,target]\n",
    "                    x = targetdf.drop(target, axis=1)\n",
    "                    if method_for_emb == 'Lasso':\n",
    "                        reg=LassoCV()\n",
    "                        reg.fit(x,y)\n",
    "                        coef_df = pd.DataFrame({'Features': x.columns, 'Coefficients': reg.coef_})\n",
    "                        if display_restrict == 'No':\n",
    "                            output_embresult = dash_table.DataTable(data=coef_df.to_dict('records')) \n",
    "                        else:\n",
    "                            nonzero_mask = (coef_df['Coefficients'] != 0)\n",
    "                            temp = coef_df.loc[nonzero_mask]\n",
    "                            feature_names = temp.loc[:, 'Features'].tolist()\n",
    "                            output_embresult = dash_table.DataTable(data=temp.to_dict('records')) \n",
    "                    elif method_for_emb == 'Ridge':\n",
    "                        ridgecv=RidgeCV()\n",
    "                        ridgecv.fit(x,y)\n",
    "                        coef_df = pd.DataFrame({'Features': x.columns, 'Coefficients': ridgecv.coef_})\n",
    "                        temp = coef_df[coef_df['Coefficients'] >= display_restrict].reset_index(drop=True)\n",
    "                        feature_names = temp.loc[:, 'Features'].tolist()\n",
    "                        output_embresult = dash_table.DataTable(data=temp.to_dict('records')) \n",
    "                    elif method_for_emb == 'Elastic nets':\n",
    "                        e_net = ElasticNet(alpha = 1)\n",
    "                        e_net.fit(x, y)\n",
    "                        ecoef_df = pd.DataFrame({'Features': x.columns, 'Coefficients': e_net.coef_})\n",
    "                        temp = ecoef_df[ecoef_df['Coefficients'] >= display_restrict].reset_index(drop=True)\n",
    "                        feature_names = temp.loc[:, 'Features'].tolist()\n",
    "                        output_embresult = dash_table.DataTable(data=temp.to_dict('records')) \n",
    "                    elif method_for_emb == 'Tree-base':\n",
    "                        model = RandomForestRegressor(n_estimators=340)\n",
    "                        model.fit(x, y)\n",
    "                        importances = model.feature_importances_\n",
    "                        final_df = pd.DataFrame({\"Features\": x.columns, \"Importances\":importances})\n",
    "                        final_df.set_index('Importances')\n",
    "                        temp = final_df[final_df['Importances'] >= display_restrict].reset_index(drop=True)\n",
    "                        feature_names = temp.loc[:, 'Features'].tolist()\n",
    "                        output_embresult = dash_table.DataTable(data=temp.to_dict('records')) \n",
    "                    if n_clicks:\n",
    "                        self.data_frame=self.data_frame.loc[:,list(feature_names)+[target]]\n",
    "                        self.data_frame2=self.data_frame2.loc[:,feature_names]\n",
    "                        confirm_ = html.H5('success',style={'text-align': 'center','color':'green'})\n",
    "                    \n",
    "            return output_embresult, confirm_\n",
    "        \n",
    "# =======================================================================================================================\n",
    "\n",
    "        #第10頁   \n",
    "        page10_layout = html.Div(\n",
    "            children=[\n",
    "                html.Br(),\n",
    "                html.H1(\"Prediction\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div(id=\"warn\",style={'color': \"rgb(220, 121, 106)\",\"font-size\": \"22px\"}),\n",
    "                html.Br(),\n",
    "                \n",
    "                #選演算法\n",
    "                html.H3(\"Select the desired algorithm:\",style={'text-align': 'left'}),\n",
    "                dcc.Dropdown(id=\"alg\",\n",
    "                            options=[{'label':'XGBRegressor','value':'XGBRegressor'},\n",
    "                                     {'label':'LGBMRegressor','value':'LGBMRegressor'},\n",
    "                                     {'label':'LinearRegressor','value':'LinearRegressor'},\n",
    "                                     {'label':'GradientBoostingRegressor','value':'GradientBoostingRegressor'},],\n",
    "                            multi=False,value='LinearRegressor',\n",
    "                            style={'width':\"70%\"}),\n",
    "                html.Br(),\n",
    "                \n",
    "                #問使用者要不要用PCA\n",
    "                html.H3(\"If you want to conduct PCA decomposition, choose the n_components you want:\",style={'text-align': 'left'}),\n",
    "                dcc.Dropdown(id=\"PCA_com\",\n",
    "                             options=[\n",
    "                                      {'label': '1', 'value': 1},\n",
    "                                      {'label': '2', 'value': 2},\n",
    "                                      {'label': '3', 'value': 3},\n",
    "                                      {'label': '4', 'value': 4},\n",
    "                                      {'label': '5', 'value': 5},\n",
    "                                      {'label': 'No', 'value': 'No'}\n",
    "                                     ],\n",
    "                            multi=False,\n",
    "                            value=\"No\",\n",
    "                            style={'width': \"70%\"}\n",
    "                ),\n",
    "                html.Br(),\n",
    "                html.H3(\"If you want to use optuna to optimize hyperparameters\",style={'text-align': 'left'}),\n",
    "                html.Br(),\n",
    "                dcc.RadioItems(id=\"optuna-radioitems\",\n",
    "                       options=[\"no\", \"yes\"], value=\"no\",\n",
    "                       labelStyle={'display': 'inline-block', 'margin-right': '10px'}),\n",
    "                \n",
    "                #等使用者調整好所有項目再開始update(讓他按按鈕)\n",
    "                html.Div([html.Button('Start Training!', id='train-button',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                      style={'textAlign': 'center', 'position': 'relative'}),\n",
    "                html.Br(),\n",
    "                dbc.Spinner(html.Div(id=\"warn\",style={'text-align': 'center'}),color=\"primary\"),\n",
    "                html.Br(),\n",
    "                \n",
    "                #結果(train資料)呈現 某種分數之類的\n",
    "                html.H3(\"Which metric would you like to use as the evaluation criterion?\",style={'text-align': 'center'}),\n",
    "                html.Div([dcc.Dropdown(id=\"metrics\",\n",
    "                             options=[\n",
    "                                      {'label': 'RMSE', 'value':'RMSE'},\n",
    "                                      {'label': 'R-squared', 'value':'R-squared'},\n",
    "                                      {'label': 'MAE', 'value':'MAE'}\n",
    "                                     ],\n",
    "                            multi=False,\n",
    "                            value='',\n",
    "                            style={'width': '80%','text-align': 'center'}\n",
    "                            )],style={'display': 'flex', 'justify-content': 'center', 'align-items': 'center','margin-left': '13%'}),\n",
    "                \n",
    "                html.Br(),\n",
    "                html.Div(id='warnformodel',style={'text-align': 'center'}),\n",
    "                html.Div(id='train_result',style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                \n",
    "                #確認要用現有模型來預測 \n",
    "                html.H3(\"click cofirm to make a prediction in test set\",style={'text-align': 'center'}),\n",
    "                html.Br(),\n",
    "                html.Div([html.Button('confirm', id='yes-button',n_clicks=0,style={'text-align': 'center','background-color': 'rgb(190, 223, 210)'})],\n",
    "                      style={'textAlign': 'center', 'position': 'relative'}),\n",
    "                \n",
    "                #結果table\n",
    "                html.Br(),\n",
    "                html.Br(),\n",
    "                html.H3(\"Prediction result\",style={'text-align': 'left'}),\n",
    "                html.Br(),\n",
    "                html.Div(dash_table.DataTable(id=\"pre_data\",page_size=10,\n",
    "                                              export_format='csv',\n",
    "                                              export_headers='none'\n",
    "                                              ),\n",
    "                         style={'width': '50%','padding': '10px'},\n",
    "                        ),\n",
    "                html.Br()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        @app.callback(\n",
    "            Output(component_id='warn', component_property='children'),\n",
    "            Output(component_id='warnformodel', component_property='children'),\n",
    "            Input(component_id='alg', component_property='value'),\n",
    "            Input(component_id='PCA_com', component_property='value'),\n",
    "            Input(component_id='train-button', component_property='n_clicks'),\n",
    "            Input(component_id=\"optuna-radioitems\", component_property='value'),\n",
    "            State(component_id='pre_data', component_property='data'), \n",
    "            State(component_id='pre_data', component_property='columns')\n",
    "            \n",
    "        )\n",
    "\n",
    "        def update_plotp6(alg,PCA_com,n_clicks1,optunause,data,columns):\n",
    "            def anyNone(*args):\n",
    "                for i in args:\n",
    "                    if i is None:\n",
    "                        return True\n",
    "                    \n",
    "            # default value\n",
    "            targetdf = None if (self.data_frame is None) else (self.data_frame)\n",
    "            testdf = None if (self.data_frame2 is None) else (self.data_frame2)\n",
    "            target = self.target_column\n",
    "            np.set_printoptions(precision=2, suppress=True)\n",
    "            result = None\n",
    "            warn = html.H5(\"you haven't upload your data.\",style={'color': \"red\"})\n",
    "            outcome='please do the prediction first.'\n",
    "            if not anyNone(target,targetdf,testdf,alg,PCA_com) and target in targetdf.columns:\n",
    "                result = np.zeros((testdf.shape[0], 2))\n",
    "                result[:, 0] = [i for i in range(testdf.shape[0])] \n",
    "                result[:, 1] = 0\n",
    "                result = pd.DataFrame(result)\n",
    "                result = result.to_dict('records')\n",
    "                \n",
    "                #如果訓練集有缺失資料 \n",
    "                missing_values = self.data_frame.isna().any().any()\n",
    "                if missing_values:\n",
    "                    warn = html.H5(\"Please go to 'Missing Value Imputing' to fill in missing values first!\",style={'color': \"red\"})\n",
    "                    outcome =html.H5(\"Click the 'Start Training' button to let me know that you have set the parameters.\",style={'color': \"red\"})\n",
    "                else: #確定沒有缺失值\n",
    "                    if not n_clicks1: #還沒按開始訓練\n",
    "                        warn = html.H5(\"Click the 'Start Training' button to let me know that you have set the parameters.\",style={'color': \"red\"})\n",
    "                    elif PCA_com != 'No':\n",
    "                        if int(PCA_com) > len(targetdf.columns)-1: #PCA降維後的特徵數大於所選for training的特徵數\n",
    "                            outcome = html.H5(\"The number of PCA components cannot exceed the number of selected features.\",style={'color': \"red\"})\n",
    "                        else:\n",
    "                            outcome={}\n",
    "                            if alg == 'LinearRegressor':\n",
    "                                #LR with PCA\n",
    "                                x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                                y = self.data_frame.loc[:,target]\n",
    "                                x_test=self.data_frame2.loc[:,x.columns]  \n",
    "                                pca = PCA(n_components=PCA_com)\n",
    "                                pca.fit(x)\n",
    "                                x = pca.transform(x)\n",
    "                                x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                                if optunause ==\"yes\":\n",
    "                                    #optuna\n",
    "                                    def objective_lr(trial):\n",
    "                                        params = {\n",
    "                                                 'n_jobs': trial.suggest_int('n_jobs', 1, 5),\n",
    "                                                 'fit_intercept': trial.suggest_categorical('fit_intercept', [True,False]),\n",
    "                                                 'copy_X': trial.suggest_categorical('copy_X', [True,False]),\n",
    "                                                 'positive': trial.suggest_categorical('positive', [True,False]),\n",
    "                                             }\n",
    "                                        reg = LinearRegression(**params)\n",
    "                                        reg.fit(x_train, y_train)\n",
    "                                        return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                    study = optuna.create_study(direction='minimize')\n",
    "                                    study.optimize(objective_lr, n_trials = 20)\n",
    "                                    #fit\n",
    "                                    model=LinearRegression(**study.best_trial.params)\n",
    "                                else:\n",
    "                                    model=LinearRegression()\n",
    "                                model.fit(x_train,y_train)\n",
    "                                \n",
    "                                #模型表現\n",
    "                                y_pred=model.predict(x_valid)\n",
    "                                rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                                score = model.score(x_train, y_train)\n",
    "                                mae = mean_absolute_error(y_valid, y_pred)\n",
    "                                self.train_outcome=[rmse,score,mae]\n",
    "                                x_test = pca.transform(x_test)\n",
    "                                result=model.predict(x_test)\n",
    "                                result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                                result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                                self.result = result.to_dict('records')\n",
    "                                \n",
    "                            elif alg == 'XGBRegressor':\n",
    "                                x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                                y = self.data_frame.loc[:,target]\n",
    "                                x_test=self.data_frame2.loc[:,x.columns]\n",
    "                                pca = PCA(n_components=PCA_com)\n",
    "                                pca.fit(x)\n",
    "                                x = pca.transform(x)\n",
    "                                x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                                if optunause ==\"yes\":\n",
    "                                    \n",
    "                                    #optuna\n",
    "                                    def objective_xgb(trial):\n",
    "                                        params = {\n",
    "                                                 'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                                                 \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "                                                 'n_estimators': trial.suggest_int('n_estimators', 100, 500, 25),\n",
    "                                                 'eta': trial.suggest_float(\"eta\", 1e-8, 1.0, log=True),\n",
    "                                                 'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "                                                 'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "                                                 'gamma': trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n",
    "                                                 'min_child_weight': trial.suggest_int('min_child_weight', 2, 10),\n",
    "                                                 'grow_policy': trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "                                                 \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0)\n",
    "                                             }\n",
    "                                        reg = XGBRegressor(**params, random_state=42)\n",
    "                                        reg.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric='rmse', verbose=True)\n",
    "                                        return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                    study = optuna.create_study(direction='minimize')\n",
    "                                    study.optimize(objective_xgb, n_trials = 20)\n",
    "                                    \n",
    "                                    #fit\n",
    "                                    model=XGBRegressor(**study.best_trial.params,random_state=42)\n",
    "                                else:\n",
    "                                    model=XGBRegressor()\n",
    "                                model.fit(x_train,y_train)\n",
    "                                \n",
    "                                #模型表現\n",
    "                                y_pred=model.predict(x_valid)\n",
    "                                rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                                score = model.score(x_train, y_train)\n",
    "                                mae = mean_absolute_error(y_valid, y_pred)\n",
    "                                self.train_outcome=[rmse,score,mae]\n",
    "                                x_test = pca.transform(x_test)\n",
    "                                result=model.predict(x_test)\n",
    "                                result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                                result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                                self.result = result.to_dict('records')\n",
    "                            elif alg == 'LGBMRegressor':\n",
    "                                x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                                y = self.data_frame.loc[:,target]\n",
    "                                x_test=self.data_frame2.loc[:,x.columns]\n",
    "                                pca = PCA(n_components=PCA_com)\n",
    "                                pca.fit(x)\n",
    "                                x = pca.transform(x)\n",
    "                                x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                                if optunause ==\"yes\":\n",
    "                                    \n",
    "                                    #optuna\n",
    "                                    def objective_lgb(trial):\n",
    "                                        params = {\n",
    "                                                'n_estimators': trial.suggest_int('n_estimators', 100,500,25),\n",
    "                                                'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 1),\n",
    "                                                'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 1),\n",
    "                                                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "                                                'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "                                                'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1),\n",
    "                                                'max_depth': trial.suggest_int('max_depth', 2, 30),\n",
    "                                                'num_leaves' : trial.suggest_int('num_leaves', 2, 1000),\n",
    "                                                'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "                                                'cat_smooth' : trial.suggest_int('min_data_per_groups', 10, 100)\n",
    "                                             }\n",
    "                                        reg = lgb.LGBMRegressor(**params, random_state=42)\n",
    "                                        reg.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric='rmse', verbose=True)\n",
    "                                        return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                    study = optuna.create_study(direction='minimize')\n",
    "                                    study.optimize(objective_lgb, n_trials = 20)\n",
    "                                    \n",
    "                                    #fit\n",
    "                                    model=lgb.LGBMRegressor(**study.best_trial.params)\n",
    "                                else:\n",
    "                                    model=lgb.LGBMRegressor()\n",
    "                                model.fit(x_train,y_train)\n",
    "                                \n",
    "                                #模型表現\n",
    "                                y_pred=model.predict(x_valid)\n",
    "                                rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                                score = model.score(x_train, y_train)\n",
    "                                mae = mean_absolute_error(y_valid, y_pred)\n",
    "                                self.train_outcome=[rmse,score,mae]\n",
    "                                \n",
    "                                x_test = pca.transform(x_test)\n",
    "                                result=model.predict(x_test)\n",
    "                                result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                                result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                                self.result = result.to_dict('records')\n",
    "                            elif alg == 'GradientBoostingRegressor':\n",
    "                                x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                                y = self.data_frame.loc[:,target]\n",
    "                                x_test=self.data_frame2.loc[:,x.columns]\n",
    "                                pca = PCA(n_components=PCA_com)\n",
    "                                pca.fit(x)\n",
    "                                x = pca.transform(x)\n",
    "                                x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                                if optunause ==\"yes\":\n",
    "                                    \n",
    "                                    #optuna\n",
    "                                    def objective_gbdt(trial):\n",
    "                                        params = {\n",
    "                                                'n_estimators': trial.suggest_int('n_estimators', 100, 500, 25),\n",
    "                                                'max_features':trial.suggest_int(\"max_features\", 10,50,5),\n",
    "                                                'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "                                                'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1),\n",
    "                                                'max_depth': trial.suggest_int('max_depth', 2, 30),\n",
    "                                                \"min_samples_split\": trial.suggest_int('min_samples_split', 2, 7),\n",
    "                                             }\n",
    "                                        reg = GradientBoostingRegressor(**params, random_state=42)\n",
    "                                        reg.fit(x_train, y_train)\n",
    "                                        return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                    study = optuna.create_study(direction='minimize')\n",
    "                                    study.optimize(objective_gbdt, n_trials = 20)\n",
    "                                    \n",
    "                                    #fit\n",
    "                                    model=GradientBoostingRegressor(**study.best_trial.params)\n",
    "                                else:\n",
    "                                    model=GradientBoostingRegressor()\n",
    "                                model.fit(x_train,y_train)\n",
    "                                \n",
    "                                #模型表現\n",
    "                                y_pred=model.predict(x_valid)\n",
    "                                rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                                score = model.score(x_train, y_train)\n",
    "                                mae = mean_absolute_error(y_valid, y_pred)\n",
    "                                self.train_outcome=[rmse,score,mae]\n",
    "                                x_test = pca.transform(x_test)\n",
    "                                result=model.predict(x_test)\n",
    "                                result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                                result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                                self.result = result.to_dict('records')\n",
    "                            warn=html.H5(\"training complete!!\",style={'color': \"green\"})            \n",
    "                    else:\n",
    "                        outcome={}\n",
    "                        if alg == 'LinearRegressor':\n",
    "                            x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                            y = self.data_frame.loc[:,target]\n",
    "                            x_test=self.data_frame2.loc[:,x.columns]\n",
    "                            x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                            if optunause ==\"yes\":\n",
    "                                \n",
    "                                #optuna\n",
    "                                def objective_lr(trial):\n",
    "                                    params = {\n",
    "                                             'n_jobs': trial.suggest_int('n_jobs', 1, 5),\n",
    "                                             'fit_intercept': trial.suggest_categorical('fit_intercept', [True,False]),\n",
    "                                             'copy_X': trial.suggest_categorical('copy_X', [True,False]),\n",
    "                                             'positive': trial.suggest_categorical('positive', [True,False]),\n",
    "                                         }\n",
    "                                    reg = LinearRegression(**params)\n",
    "                                    reg.fit(x_train, y_train)\n",
    "                                    return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                study = optuna.create_study(direction='minimize')\n",
    "                                study.optimize(objective_lr, n_trials = 20)\n",
    "                                #fit\n",
    "                                model=LinearRegression(**study.best_trial.params)\n",
    "                            else:\n",
    "                                model=LinearRegression()\n",
    "                            model.fit(x_train,y_train)\n",
    "                            \n",
    "                            #模型表現\n",
    "                            y_pred=model.predict(x_valid)\n",
    "                            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                            score = model.score(x_train, y_train)\n",
    "                            mae = mean_absolute_error(y_valid, y_pred)\n",
    "                            self.train_outcome=[rmse,score,mae]\n",
    "                            result=model.predict(x_test)\n",
    "                            result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                            result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                            self.result = result.to_dict('records')\n",
    "                        elif alg == 'XGBRegressor':\n",
    "                            x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                            y = self.data_frame.loc[:,target]\n",
    "                            x_test=self.data_frame2.loc[:,x.columns]\n",
    "                            x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                            if optunause ==\"yes\":\n",
    "                                \n",
    "                                #optuna\n",
    "                                def objective_xgb(trial):\n",
    "                                    params = {\n",
    "                                             'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                                             \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "                                             'n_estimators': trial.suggest_int('n_estimators', 100, 500, 25),\n",
    "                                             'eta': trial.suggest_float(\"eta\", 1e-8, 1.0, log=True),\n",
    "                                             'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "                                             'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "                                             'gamma': trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n",
    "                                             'min_child_weight': trial.suggest_int('min_child_weight', 2, 10),\n",
    "                                             'grow_policy': trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "                                             \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0)\n",
    "                                         }\n",
    "                                    reg = XGBRegressor(**params, random_state=42)\n",
    "                                    reg.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric='rmse', verbose=True)\n",
    "                                    return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                study = optuna.create_study(direction='minimize')\n",
    "                                study.optimize(objective_xgb, n_trials = 20)\n",
    "                                \n",
    "                                #fit\n",
    "                                model=XGBRegressor(**study.best_trial.params,random_state=42)\n",
    "                            else:\n",
    "                                model=XGBRegressor()\n",
    "                            model.fit(x_train,y_train)\n",
    "                            \n",
    "                            #模型表現\n",
    "                            y_pred=model.predict(x_valid)\n",
    "                            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                            score = model.score(x_train, y_train)\n",
    "                            mae = mean_absolute_error(y_valid, y_pred)\n",
    "                            self.train_outcome=[rmse,score,mae]\n",
    "                            result=model.predict(x_test)\n",
    "                            result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                            result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                            self.result = result.to_dict('records')\n",
    "                        elif alg == 'GradientBoostingRegressor':\n",
    "                            x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                            y = self.data_frame.loc[:,target]\n",
    "                            x_test=self.data_frame2.loc[:,x.columns]\n",
    "                            x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                            if optunause ==\"yes\":\n",
    "                                \n",
    "                                #optuna\n",
    "                                def objective_gbdt(trial):\n",
    "                                    params = {\n",
    "                                            'n_estimators': trial.suggest_int('n_estimators', 100, 500, 25),\n",
    "                                            'max_features':trial.suggest_int(\"max_features\", 10,50,5),\n",
    "                                            'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "                                            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1),\n",
    "                                            'max_depth': trial.suggest_int('max_depth', 2, 30),\n",
    "                                            \"min_samples_split\": trial.suggest_int('min_samples_split', 2, 7),\n",
    "                                         }\n",
    "                                    reg = GradientBoostingRegressor(**params, random_state=42)\n",
    "                                    reg.fit(x_train, y_train)\n",
    "                                    return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                study = optuna.create_study(direction='minimize')\n",
    "                                study.optimize(objective_gbdt, n_trials = 20)\n",
    "                                \n",
    "                                #fit\n",
    "                                model=GradientBoostingRegressor(**study.best_trial.params)\n",
    "                            else:\n",
    "                                model=GradientBoostingRegressor()\n",
    "                            model.fit(x_train,y_train)\n",
    "                            \n",
    "                            #模型表現\n",
    "                            y_pred=model.predict(x_valid)\n",
    "                            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                            score = model.score(x_train, y_train)\n",
    "                            mae = mean_absolute_error(y_valid, y_pred)\n",
    "                            self.train_outcome=[rmse,score,mae]\n",
    "                            \n",
    "                            result=model.predict(x_test)\n",
    "                            result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                            result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                            self.result = result.to_dict('records')\n",
    "                        elif alg == 'LGBMRegressor':\n",
    "                            x = self.data_frame.drop(columns=target) #取出想要的欄位\n",
    "                            y = self.data_frame.loc[:,target]\n",
    "                            x_test=self.data_frame2.loc[:,x.columns]\n",
    "                            x_train,x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "                            if optunause ==\"yes\":\n",
    "                                \n",
    "                                #optuna\n",
    "                                def objective_lgb(trial):\n",
    "                                    params = {\n",
    "                                            'n_estimators': trial.suggest_int('n_estimators', 100,500,25),\n",
    "                                            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 1),\n",
    "                                            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 1),\n",
    "                                            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "                                            'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "                                            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1),\n",
    "                                            'max_depth': trial.suggest_int('max_depth', 2, 30),\n",
    "                                            'num_leaves' : trial.suggest_int('num_leaves', 2, 1000),\n",
    "                                            'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "                                            'cat_smooth' : trial.suggest_int('min_data_per_groups', 10, 100)\n",
    "                                         }\n",
    "                                    reg = lgb.LGBMRegressor(**params, random_state=42)\n",
    "                                    reg.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric='rmse', verbose=True)\n",
    "                                    return mean_squared_error(y_valid, reg.predict(x_valid), squared=False)\n",
    "                                study = optuna.create_study(direction='minimize')\n",
    "                                study.optimize(objective_lgb, n_trials = 20)\n",
    "                                \n",
    "                                #fit\n",
    "                                model=lgb.LGBMRegressor(**study.best_trial.params)\n",
    "                            else:\n",
    "                                model=lgb.LGBMRegressor()\n",
    "                            model.fit(x_train,y_train)\n",
    "                            \n",
    "                            #模型表現\n",
    "                            y_pred=model.predict(x_valid)\n",
    "                            rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "                            score = model.score(x_train, y_train)\n",
    "                            mae = mean_absolute_error(y_valid, y_pred)\n",
    "                            self.train_outcome=[rmse,score,mae]\n",
    "                            \n",
    "                            result=model.predict(x_test)\n",
    "                            result = pd.DataFrame(result,columns=[\"Result\"])\n",
    "                            result.insert(loc=0, column='Index', value=[i for i in range(self.data_frame2.shape[0])])\n",
    "                            self.result = result.to_dict('records')\n",
    "                        warn=html.H5(\"training complete!!\",style={'color': \"green\"})\n",
    "            return warn,outcome\n",
    "        @app.callback(\n",
    "            Output(component_id='train_result', component_property='children'),\n",
    "            Input(component_id='metrics', component_property='value'),\n",
    "        )    \n",
    "        def metrics(metrics):\n",
    "            if self.train_outcome is not None:\n",
    "                if metrics == 'RMSE':\n",
    "                    outcome = f'RMSE:{self.train_outcome[0]:.3f}'\n",
    "                elif metrics == 'R-squared':\n",
    "                    outcome = f'R-squared:{self.train_outcome[1]:.3f}'\n",
    "                elif metrics == 'MAE':\n",
    "                    outcome = f'MAE:{self.train_outcome[2]:.3f}'\n",
    "                else:\n",
    "                    outcome={}\n",
    "            else:\n",
    "                outcome={}\n",
    "            return outcome\n",
    "\n",
    "        @app.callback(\n",
    "            Output(component_id='pre_data', component_property='data'),\n",
    "            Input(component_id='yes-button', component_property='n_clicks'),\n",
    "        )    \n",
    "        def metrics(n_clicks2):\n",
    "            if n_clicks2:\n",
    "                result=self.result\n",
    "            else:\n",
    "                if self.data_frame2 is not None and self.data_frame is not None:\n",
    "                    result = np.zeros((self.data_frame2.shape[0], 2))\n",
    "                    result[:, 0] = [i for i in range(self.data_frame2.shape[0])] \n",
    "                    result[:, 1] = 0\n",
    "                    result = pd.DataFrame(result)\n",
    "                    result = result.to_dict('records')\n",
    "                    \n",
    "                else:\n",
    "                    result = np.zeros((10, 2))\n",
    "                    result[:, 0] = [i for i in range(10)] \n",
    "                    result[:, 1] = 0\n",
    "                    result = pd.DataFrame(result)\n",
    "                    result = result.to_dict('records')\n",
    "            return result\n",
    "# =======================================================================================================================\n",
    "        @app.callback(\n",
    "            Output('page-content', 'children'),\n",
    "            [Input('url', 'pathname')])\n",
    "    \n",
    "        def display_page(pathname):\n",
    "            if pathname == '/page0':\n",
    "                return page0_layout\n",
    "            elif pathname == '/page1':\n",
    "                return page1_layout\n",
    "            elif pathname == '/page2':\n",
    "                return page2_layout\n",
    "            elif pathname == '/page3':\n",
    "                return page3_layout\n",
    "            elif pathname == '/page4':\n",
    "                return page4_layout\n",
    "            elif pathname == '/page5':\n",
    "                return page5_layout\n",
    "            elif pathname == '/page6':\n",
    "                return page6_layout\n",
    "            elif pathname == '/page7':\n",
    "                return page7_layout\n",
    "            elif pathname == '/page8':\n",
    "                return page8_layout\n",
    "            elif pathname == '/page9':\n",
    "                return page9_layout\n",
    "            elif pathname == '/page10':\n",
    "                return page10_layout\n",
    "            else:\n",
    "                return page0_layout\n",
    "            \n",
    "            \n",
    "        app.run_server(debug=True,use_reloader=False,port=5674)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0142a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:5674/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "MyDash2().run_dash()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
